- id: assess_subject_bold_dropout
  name: Check nifti masker mask overlap to assess subject dropout
  stage: preprocessing
  description: 'The overlap of the individual masker masks with a generous aggregate
    mask (voxels with data for at least 30% of the subjects) is used to identify subjects
    with poor coverage that may be considered for  removal. A final list of subjects
    to use in first-level analyses is created.

    '
  code_dir: analyses/assess_subject_bold_dropout
  dependencies: []
  script_entry:
  - visualize_masker_on_mean_bold.py
  - submit_visualize_masker_on_mean_bold.py
  notebook_entry:
  - generate_good_subject_list.ipynb
  other_files:
  - analyses/assess_subject_bold_dropout/preanalysis_good_subject_list.txt
  - 'group mask for randomise: .../survey_medley_results/assess_subject_bold_dropout/group_mask_intersection_30pct.nii.gz'
  output_dir: /oak/stanford/groups/russpold/data/uh2/aim1/derivatives/survey_medley_results/assess_subject_bold_dropout/nifti_masker_masks
  hypothesis: Some subjects with poor data may have been missed during MRIQC evaluation.
  conclusion: Two subjects were identified for removal due to poor coverage caused
    by bad data quality (see notebook for details).
  notes: 'For time series analyses used subjects listed in preanalysis_good_subject_list.txt
    (in associated analysis directory).   A mask for group (randomise) analyses is
    created in this code base (see other files section for mask location.)

    '
  status: completed
  last_updated: '2025-11-23'
  authors:
  - Jeanette Mumford
- id: create_events_modified
  name: Modify events files to create consistent scale and adjust question codings
  stage: preprocessing
  description: "Modified the events files in order to make all responses on a scale\
    \ of 0\u20131, and code the responses such that a higher response corresponded\
    \ to greater self-regulation.\n"
  code_dir: analyses/create_events_modified
  dependencies: []
  script_entry:
  - fix_codings.py
  notebook_entry: null
  other_files: []
  output_dir: null
  hypothesis: null
  conclusion: null
  notes: null
  status: completed
  last_updated: 2025-11-18
  authors:
  - Jaemon Jumpawong
- id: questionnaire_brain_behavior_slope_ftest
  name: Assess how within-subject brain-behavior slopes differ between questionnaires
  stage: group
  description: 'Run an F-test on the within-subject slopes between brain activation
    and behavioral response for each questionnaire,  to see whether any within-questionnaire
    slopes are statistically different from each other.

    '
  code_dir: analyses/questionnaire_brain_behavior_slope_ftest
  dependencies:
  - analyses/within_subject_brain_behavior_by_questionnaire
  script_entry: []
  notebook_entry:
  - run_ftest.ipynb
  other_files: []
  output_dir: oak/stanford/groups/russpold/data/uh2/aim1/derivatives/survey_medley_results/questionnaire_brain_behavior_slope_ftest
  hypothesis: Some within-questionnaire slopes statistically differ from each other
    in some parts of the brain.
  conclusion: 'Still under discussion, but the F-test yielded some significant regions,  some
    of which overlapped with the regions found in the within-subject brain-behavior
    analysis with all questions.

    '
  notes: null
  status: ongoing
  last_updated: 2025-11-16
  authors:
  - Jaemon Jumpawong
  - Jeanette Mumford
- id: questionnaire_average_omnibus_f
  name: Run and process omnibus f comparing all pairs of questionnaire average activation
    estimates
  stage: group
  description: 'We use randomise to run an omnibus f-test to test whether any pair
    of questionaire average activations differ from each other.  The permutation scheme
    adjusts for the correlations between measures within-subject in the group model
    (model mean adjusts by subject as well).  Individual paired t-tests for all 10
    pairs of  questionnaires are also run in an effort to help understand the f-test
    results.

    '
  code_dir: analyses/questionnaire_average_omnibus_f
  dependencies:
  - Output files from within_subject_question_estimates analysis
  script_entry:
  - randomise scripts are created in group_ftest and each subdirectory of all_paired_t_tests
    in survey_medley_results/within_subject_question_estimates/
  notebook_entry:
  - setup_randomise.ipynb
  - review_results.ipynb
  results_files:
  - review_results.ipynb
  other_files:
  - 'runs f-test randomise script: submit_randomise.batch'
  - 'runs individual paired randomise tests: submis_randomise_all_pairs.batch'
  output_dir: /oak/stanford/groups/russpold/data/uh2/aim1/derivatives/survey_medley_results/within_subject_question_estimates/within_subject_question_estimates/
  hypothesis: Some questionnaire-based average activation estimates will differ from
    others.
  conclusion: There is a strong result for the omnibus f-test, but Patrick needs to
    review the individual paired comparisons.
  notes: 'The paired comparisons can be used to conclude where differences  DO occur,
    but a lack of a significant paired t-test cannot be used to conclude two questionnaires
    are the same.  Keep in mind that questionnaires with fewer questions have less
    power in these comparisons.

    '
  status: Results files needs review by Patrick
  last_updated: 2025-11-25
  authors:
  - Jeanette Mumford
  - Jaemon Jumpawong
- id: within_subject_brain_behavior_analysis
  name: Assess within-subject brain-behavior correlations
  stage: time series
  description: 'Estimate the average of the within-subject correlation between brain  activation
    and behavioral response across all questions.

    '
  code_dir: analyses/within_subject_brain_behavior_analysis
  dependencies: []
  script_entry:
  - within_subject_brain_behavior_outlier_analysis.py
  - run_outlier_analysis.batch
  - submit_randomise.sh
  notebook_entry:
  - analyze_brain_behavior_within_subject.ipynb
  other_files: []
  output_dir: oak/stanford/groups/russpold/data/uh2/aim1/derivatives/survey_medley_results/within_subject_brain_behavior_analysis
  hypothesis: Within-subject brain activation linearly relates to their behavioral
    response.
  conclusion: 'There are regions with a significant negative correlation between brain
    activation and behavioral response (across all questions), suggesting that these
    regions are more activated when giving a response coded as less self-regulated.

    '
  notes: null
  status: completed
  last_updated: 2025-11-16
  authors:
  - Jaemon Jumpawong
  - Jeanette Mumford
- id: within_subject_brain_behavior_by_questionnaire
  name: Assess within-subject brain-behavior slopes in each questionnaire
  stage: time series and group
  description: 'Estimate the within-subject slope between brain activation and behavioral
    response separately for each questionnaire.

    '
  code_dir: analyses/within_subject_brain_behavior_by_questionnaire
  dependencies: []
  script_entry:
  - questionnaire_brain_behavior_contrasts_outlier_analysis.py
  - run_outlier_analysis.batch
  notebook_entry:
  - brain_behavior_within_subject_by_questionnaire.ipynb
  other_files: []
  output_dir: oak/stanford/groups/russpold/data/uh2/aim1/derivatives/survey_medley_results/within_subject_brain_behavior_by_questionnaire
  hypothesis: Some brain/behavior slopes are statistically different between questionnaires.
  conclusion: 'Still under discussion, but the F-test yielded some significant regions,  some
    of which overlapped with the regions found in the within-subject brain-behavior
    analysis with all questions.

    '
  notes: null
  status: completed
  last_updated: 2025-11-16
  authors:
  - Jaemon Jumpawong
  - Jeanette Mumford
- id: within_subject_question_estimates
  name: Estimate question and questionnaire activation estimates and QA
  stage: time series
  description: 'This analysis runs time series models for all subjects to estimate
    question-specific estimates as well as questionnaire-specific estimates. For the
    questionnaire averages, all question estimates were included, regardless of whether
    the subject responded or had an acceptable key press.   Contrast estimates filenames
    include "err" if they did not respond or used an unacceptable key for that question.

    '
  code_dir: analyses/within_subject_question_estimates
  dependencies: []
  script_entry:
  - timeseries_model.py
  notebook_entry:
  - make_subid_text_file.ipynb
  - qa_outputs.ipynb
  output_dir: /oak/stanford/groups/russpold/data/uh2/aim1/derivatives/survey_medley_results/within_subject_question_estimates/within_subject_results
  hypothesis: No formal hypothesis at this stage; just calculating estimates for group
    analyses to study questionnaire differences.
  conclusion: The outlier assessment worked well and we have at least 93 good data
    sets for each question/questionnaire.
  notes: 'There are lists in text files indicating the good subjects for each contrast
    (based on the outlier assessment)  located in the outlier_assessment subdirectory
    within the output directory.

    '
  status: complete
  last_updated: 2025-11-20
  authors:
  - Jeanette Mumford
  - Jaemon Jumpawong
